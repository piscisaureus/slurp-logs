{"nick":"devsnek","message":"Trott: your force push broke my smart fridge","date":"2018-11-04T00:22:28.892Z","type":"message"}
{"nick":"Trott","message":"Part of me hopes you're not actually joking just because that would be INCREDIBLE!!!","date":"2018-11-04T00:23:07.053Z","type":"message"}
{"nick":"devsnek","message":"lol","date":"2018-11-04T00:26:21.783Z","type":"message"}
{"nick":"indutny","message":"Pushing straight to the fridge'","date":"2018-11-04T00:26:32.796Z","type":"message"}
{"nick":"devsnek","message":"indutny: i'm really enjoying the generated files in llhttp","date":"2018-11-04T00:27:18.306Z","type":"message"}
{"nick":"indutny","message":"thanks! There're still ways to improve them","date":"2018-11-04T00:27:37.754Z","type":"message"}
{"nick":"devsnek","message":"verbose is fast i geuss","date":"2018-11-04T00:27:49.983Z","type":"message"}
{"nick":"devsnek","message":"guess*","date":"2018-11-04T00:27:51.954Z","type":"message"}
{"nick":"indutny","message":"I plan to move the `blob` declarations to the places that use them","date":"2018-11-04T00:28:01.840Z","type":"message"}
{"nick":"devsnek","message":"wasn't the other component that it would be able to just generate a binary directly using llvm ir","date":"2018-11-04T00:29:48.133Z","type":"message"}
{"nick":"indutny","message":"yeah, it does that","date":"2018-11-04T00:34:13.177Z","type":"message"}
{"nick":"indutny","message":"what's funny is that LLVM IR is slower than plain C","date":"2018-11-04T00:34:26.560Z","type":"message"}
{"nick":"indutny","message":"I have no idea why, and no time to investigate properly","date":"2018-11-04T00:34:39.423Z","type":"message"}
{"nick":"doodadjs","reason":"Ping timeout: 252 seconds","date":"2018-11-04T00:35:21.225Z","type":"quit"}
{"nick":"devsnek","message":"indutny: does it use the same logical output as the c?","date":"2018-11-04T00:37:13.261Z","type":"message"}
{"nick":"indutny","message":"yep","date":"2018-11-04T00:37:20.827Z","type":"message"}
{"nick":"devsnek","message":"i'm seeing a lot of stuff that gcc would optimize out","date":"2018-11-04T00:37:24.170Z","type":"message"}
{"nick":"indutny","message":"well, LLVM IR bitcode can be optimized too","date":"2018-11-04T00:37:34.834Z","type":"message"}
{"nick":"indutny","message":"What likely happens is that the tail calls that I use heavily in the bitcode are preventing the optimizations that work fine on C code","date":"2018-11-04T00:38:11.346Z","type":"message"}
{"nick":"indutny","message":"In fact, I had to disable a couple of optimizations in llvm so that it wouldn't crash during compilation","date":"2018-11-04T00:38:38.409Z","type":"message"}
{"nick":"indutny","message":"These changes are only in llvm 6.0.1 and newer","date":"2018-11-04T00:38:51.505Z","type":"message"}
{"nick":"devsnek","message":"especially those http_parser__c_test_flags methods","date":"2018-11-04T00:39:05.154Z","type":"message"}
{"nick":"indutny","message":"I'm sure that this is inlined at -O3","date":"2018-11-04T00:41:08.989Z","type":"message"}
{"nick":"indutny","message":"hell, llhttp is 2x times faster than http_parser :D","date":"2018-11-04T00:41:20.235Z","type":"message"}
{"nick":"devsnek","message":"definitely","date":"2018-11-04T00:41:23.343Z","type":"message"}
{"nick":"devsnek","message":"maybe llvm-link catches those things too","date":"2018-11-04T00:41:39.739Z","type":"message"}
{"nick":"devsnek","message":"i don't have a good sense of llvm-link behavior though","date":"2018-11-04T00:41:57.206Z","type":"message"}
{"nick":"devsnek","message":"i assume you know more than i do","date":"2018-11-04T00:42:00.708Z","type":"message"}
{"nick":"indutny","message":"I don't","date":"2018-11-04T00:42:04.265Z","type":"message"}
{"nick":"indutny","message":":)","date":"2018-11-04T00:42:05.492Z","type":"message"}
{"nick":"devsnek","message":"lol","date":"2018-11-04T00:42:06.956Z","type":"message"}
{"nick":"indutny","message":"`-flto` does some magic","date":"2018-11-04T00:42:12.205Z","type":"message"}
{"nick":"indutny","message":"but it is beyond my understanding right now","date":"2018-11-04T00:42:23.560Z","type":"message"}
{"nick":"indutny","message":"I think it might be just concatenating the bitcode from individual object files","date":"2018-11-04T00:42:41.303Z","type":"message"}
{"nick":"devsnek","message":"how come you emit those flag methods instead of just putting that single line at the location where it happens","date":"2018-11-04T00:42:42.184Z","type":"message"}
{"nick":"indutny","message":"and optimizing it all together","date":"2018-11-04T00:42:44.647Z","type":"message"}
{"nick":"indutny","message":"devsnek: that's the price for a simple API","date":"2018-11-04T00:43:06.658Z","type":"message"}
{"nick":"indutny","message":"API-wise they're similar to external function calls","date":"2018-11-04T00:43:17.406Z","type":"message"}
{"nick":"indutny","message":"so it is easier to emit the functions separately and call them","date":"2018-11-04T00:43:32.486Z","type":"message"}
{"nick":"indutny","message":"plus I don't have to limit the output to single-expression action","date":"2018-11-04T00:43:49.558Z","type":"message"}
{"nick":"indutny","message":"see `mul_add` functions","date":"2018-11-04T00:43:56.228Z","type":"message"}
{"nick":"devsnek","message":"this is setFlag right?","date":"2018-11-04T00:44:12.631Z","type":"message"}
{"nick":"indutny","message":"no, it is `llhttp__c_mul_add_content_length` ?","date":"2018-11-04T00:44:27.272Z","type":"message"}
{"nick":"indutny","message":"multiplication and addition with overflow checks","date":"2018-11-04T00:44:45.947Z","type":"message"}
{"nick":"devsnek","message":"i mean for like http_parser__c_test_flags_1","date":"2018-11-04T00:45:00.094Z","type":"message"}
{"nick":"indutny","message":"ah","date":"2018-11-04T00:45:12.427Z","type":"message"}
{"nick":"indutny","message":"`testFlags`, I guess","date":"2018-11-04T00:45:24.799Z","type":"message"}
{"nick":"devsnek","message":"oh i'm seeing it now","date":"2018-11-04T00:45:51.672Z","type":"message"}
{"nick":"indutny","message":"I should write documentation for llparse","date":"2018-11-04T00:46:18.897Z","type":"message"}
{"nick":"devsnek","message":"oh wait here we go like `http_parser__c_or_flags_3`","date":"2018-11-04T00:46:28.807Z","type":"message"}
{"nick":"devsnek","message":"that looks like the output of setFlag","date":"2018-11-04T00:46:46.902Z","type":"message"}
{"nick":"indutny","message":"yep","date":"2018-11-04T00:46:51.266Z","type":"message"}
{"nick":"indutny","message":"it is `p.code.or('flags')`","date":"2018-11-04T00:47:04.534Z","type":"message"}
{"nick":"devsnek","message":"ye","date":"2018-11-04T00:47:07.086Z","type":"message"}
{"nick":"devsnek","message":"but somewhere between the ts and the output an entire method is introduced","date":"2018-11-04T00:47:37.185Z","type":"message"}
{"nick":"indutny","message":"in llparse","date":"2018-11-04T00:47:46.182Z","type":"message"}
{"nick":"indutny","message":"https://github.com/indutny/llparse/blob/master/src/implementation/c/code/or.ts","date":"2018-11-04T00:48:00.428Z","type":"message"}
{"nick":"indutny","message":"https://github.com/indutny/llparse/blob/master/src/implementation/c/compilation.ts#L184-L192","date":"2018-11-04T00:48:23.386Z","type":"message"}
{"nick":"devsnek","message":"is that like a safety for the fact that you're generating strings of C","date":"2018-11-04T00:48:36.126Z","type":"message"}
{"nick":"indutny","message":"https://github.com/indutny/llparse/blob/master/src/implementation/c/code/field.ts#L7-L21","date":"2018-11-04T00:48:50.884Z","type":"message"}
{"nick":"indutny","message":"what is exactly is a safety?","date":"2018-11-04T00:49:03.894Z","type":"message"}
{"nick":"devsnek","message":"i would expect it to just put the |= at the actual site where its being used","date":"2018-11-04T00:49:03.973Z","type":"message"}
{"nick":"indutny","message":"what do you mean","date":"2018-11-04T00:49:08.772Z","type":"message"}
{"nick":"indutny","message":"ah","date":"2018-11-04T00:49:11.238Z","type":"message"}
{"nick":"indutny","message":"I see","date":"2018-11-04T00:49:13.345Z","type":"message"}
{"nick":"devsnek","message":"yeah i don't get why you do that whole method building thing","date":"2018-11-04T00:49:26.213Z","type":"message"}
{"nick":"indutny","message":"well, because it calls external methods in the same way","date":"2018-11-04T00:49:45.483Z","type":"message"}
{"nick":"indutny","message":"`p.invoke(p.code.match())` and so on","date":"2018-11-04T00:50:10.546Z","type":"message"}
{"nick":"indutny","message":"it was just easier to do it this way","date":"2018-11-04T00:50:19.173Z","type":"message"}
{"nick":"devsnek","message":"so its another place for optimization","date":"2018-11-04T00:50:31.664Z","type":"message"}
{"nick":"indutny","message":"possibly, but not necessarily","date":"2018-11-04T00:50:44.457Z","type":"message"}
{"nick":"indutny","message":"compiler optimizes it away at -O3","date":"2018-11-04T00:50:51.628Z","type":"message"}
{"nick":"devsnek","message":"that doesn't mean you need to give it more to chew :P","date":"2018-11-04T00:51:29.548Z","type":"message"}
{"nick":"indutny","message":"it doesn't :)","date":"2018-11-04T00:51:51.256Z","type":"message"}
{"nick":"indutny","message":"It doesn't mean that I should churn the code base for improving something that doesn't cause problems yet :D","date":"2018-11-04T00:52:08.169Z","type":"message"}
{"nick":"devsnek","message":"heh","date":"2018-11-04T00:52:13.174Z","type":"message"}
{"nick":"indutny","message":"I'm more than happy with performance of that thing. I expected it to be a bit worse than http_parser","date":"2018-11-04T00:52:44.313Z","type":"message"}
{"nick":"indutny","message":"It would be painful to convince everyone to move to llhttp in such case","date":"2018-11-04T00:52:57.649Z","type":"message"}
{"nick":"devsnek","message":"it would be kinda interesting to see what a llparse js target would look like","date":"2018-11-04T00:53:38.780Z","type":"message"}
{"nick":"devsnek","message":"maybe i'll experiment with that at some point","date":"2018-11-04T00:53:45.732Z","type":"message"}
{"nick":"indutny","message":"it should look very similar to the C","date":"2018-11-04T00:54:35.702Z","type":"message"}
{"nick":"indutny","message":"`goto ...` and big `switch`","date":"2018-11-04T00:54:47.224Z","type":"message"}
{"nick":"devsnek","message":"but js has different optimization patterns","date":"2018-11-04T00:55:08.773Z","type":"message"}
{"nick":"indutny","message":"llparse has all necessary abstractions in place for generating another outputs","date":"2018-11-04T00:55:09.369Z","type":"message"}
{"nick":"indutny","message":"true","date":"2018-11-04T00:55:13.855Z","type":"message"}
{"nick":"marthinal","date":"2018-11-04T02:19:51.521Z","type":"join"}
{"nick":"marthinal","reason":"Ping timeout: 245 seconds","date":"2018-11-04T02:24:13.315Z","type":"quit"}
{"nick":"antsmartian","date":"2018-11-04T03:17:10.958Z","type":"join"}
{"nick":"mritunjay_12","reason":"Ping timeout: 256 seconds","date":"2018-11-04T03:22:13.164Z","type":"quit"}
{"nick":"t0dd1v","date":"2018-11-04T03:56:09.692Z","type":"join"}
{"nick":"antsmartian","reason":"Remote host closed the connection","date":"2018-11-04T04:12:37.174Z","type":"quit"}
{"nick":"antsmartian","date":"2018-11-04T04:13:24.078Z","type":"join"}
{"nick":"marthinal","date":"2018-11-04T05:16:54.621Z","type":"join"}
{"nick":"marthinal","reason":"Ping timeout: 240 seconds","date":"2018-11-04T05:21:07.320Z","type":"quit"}
{"nick":"lpin","date":"2018-11-04T06:12:42.625Z","type":"join"}
{"nick":"t0dd1v","reason":"Quit: Connection closed for inactivity","date":"2018-11-04T06:15:28.471Z","type":"quit"}
{"nick":"joyee","message":"I am wondering...if node core is ever going to use ESM internally, that would not be lazy-loadable at all, right? (unless import(), but I suspect we would break a lot of things if the internal loading is async)","date":"2018-11-04T07:08:48.648Z","type":"message"}
{"nick":"marthinal","date":"2018-11-04T07:21:22.381Z","type":"join"}
{"nick":"marthinal","reason":"Remote host closed the connection","date":"2018-11-04T07:21:54.952Z","type":"quit"}
{"nick":"m00dy","date":"2018-11-04T08:14:31.463Z","type":"join"}
{"nick":"rtn","date":"2018-11-04T08:17:34.001Z","type":"join"}
{"nick":"rtn","new_nick":"ralphtheninja","date":"2018-11-04T08:17:41.815Z","type":"nick"}
{"nick":"antsmartian","reason":"Remote host closed the connection","date":"2018-11-04T09:00:48.311Z","type":"quit"}
{"nick":"seishun","date":"2018-11-04T09:23:55.841Z","type":"join"}
{"nick":"antsmartian","date":"2018-11-04T09:33:08.352Z","type":"join"}
{"nick":"antsmartian","reason":"Remote host closed the connection","date":"2018-11-04T10:27:41.919Z","type":"quit"}
{"nick":"antsmartian","date":"2018-11-04T11:28:42.577Z","type":"join"}
{"nick":"doodadjs","date":"2018-11-04T11:35:11.279Z","type":"join"}
{"nick":"seishun","reason":"Ping timeout: 250 seconds","date":"2018-11-04T11:49:52.837Z","type":"quit"}
{"nick":"seishun","date":"2018-11-04T12:28:59.015Z","type":"join"}
{"nick":"seishun","reason":"Disconnected by services","date":"2018-11-04T12:29:47.374Z","type":"quit"}
{"nick":"seishun","date":"2018-11-04T12:29:53.793Z","type":"join"}
{"nick":"gabrielschulhof","date":"2018-11-04T12:38:25.400Z","type":"join"}
{"nick":"ralphtheninja","reason":"Quit: leaving","date":"2018-11-04T12:41:07.063Z","type":"quit"}
{"nick":"lundibundi","date":"2018-11-04T13:00:10.476Z","type":"join"}
{"nick":"lundibundi","reason":"Remote host closed the connection","date":"2018-11-04T13:01:27.657Z","type":"quit"}
{"nick":"lundibundi","date":"2018-11-04T13:05:48.361Z","type":"join"}
{"nick":"lundibundi","reason":"Ping timeout: 252 seconds","date":"2018-11-04T13:33:03.223Z","type":"quit"}
{"nick":"m00dy","reason":"Ping timeout: 252 seconds","date":"2018-11-04T13:33:03.424Z","type":"quit"}
{"nick":"m00dy","date":"2018-11-04T13:39:37.608Z","type":"join"}
{"nick":"rtn","date":"2018-11-04T13:44:56.405Z","type":"join"}
{"nick":"rtn","new_nick":"ralphtheninja","date":"2018-11-04T13:45:03.653Z","type":"nick"}
{"nick":"seishun","reason":"Ping timeout: 240 seconds","date":"2018-11-04T13:49:07.391Z","type":"quit"}
{"nick":"gabrielschulhof","reason":"Ping timeout: 240 seconds","date":"2018-11-04T13:57:27.432Z","type":"quit"}
{"nick":"t0dd1v","date":"2018-11-04T14:04:41.942Z","type":"join"}
{"nick":"gabrielschulhof","date":"2018-11-04T14:13:47.453Z","type":"join"}
{"nick":"devsnek","message":"joyee: if we use mksnapshot i don' think it would really matter","date":"2018-11-04T14:38:49.124Z","type":"message"}
{"nick":"joyee","message":"devsnek: it depends on which one is more further away: mksnapshot or ESM in native modules","date":"2018-11-04T14:40:28.285Z","type":"message"}
{"nick":"devsnek","message":"well we could do ESM in native modules right now","date":"2018-11-04T14:40:48.704Z","type":"message"}
{"nick":"devsnek","message":"i would avoid it though because we don't have snapshots","date":"2018-11-04T14:40:57.661Z","type":"message"}
{"nick":"joyee","message":"Oh, wait, now come to think of it - not lazy loading would break monkey-patching","date":"2018-11-04T14:41:25.015Z","type":"message"}
{"nick":"devsnek","message":"monkey patching just means we failed to provide proper options in an api","date":"2018-11-04T14:41:55.046Z","type":"message"}
{"nick":"joyee","message":"And....snapshot would break that as well?","date":"2018-11-04T14:42:01.014Z","type":"message"}
{"nick":"devsnek","message":"like HTTPParser","date":"2018-11-04T14:42:08.162Z","type":"message"}
{"nick":"joyee","message":"devsnek: providing proper options for all of them may be even further away","date":"2018-11-04T14:42:33.919Z","type":"message"}
{"nick":"joyee","message":"Wait I remember jasnell talking about require hooks","date":"2018-11-04T14:43:11.665Z","type":"message"}
{"nick":"joyee","message":"But it can potentially be blocked out of the same reason that blocked addaleax's dynamic loading effort - wait that's also jasnell","date":"2018-11-04T14:44:06.935Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: Hey, if you have some free time, it would be great if you can have a look at this PR: https://github.com/nodejs/node/pull/22875 and tell your thoughts. Thanks much.","date":"2018-11-04T14:44:36.073Z","type":"message"}
{"nick":"devsnek","message":"if we use esm, all the exports become immutable from the consumer side","date":"2018-11-04T14:44:40.685Z","type":"message"}
{"nick":"devsnek","message":"like you couldn't replace `util.inspect`","date":"2018-11-04T14:44:53.559Z","type":"message"}
{"nick":"joyee","message":"I assume that's not acceptable?","date":"2018-11-04T14:45:02.421Z","type":"message"}
{"nick":"devsnek","message":"ðŸ¤·","date":"2018-11-04T14:45:13.461Z","type":"message"}
{"nick":"devsnek","message":"antsmartian: yeah i'll take a look","date":"2018-11-04T14:45:19.890Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: Awesome, thanks!","date":"2018-11-04T14:45:35.965Z","type":"message"}
{"nick":"devsnek","message":"antsmartain: it looks like the completion stuff has a race condition?","date":"2018-11-04T14:45:59.856Z","type":"message"}
{"nick":"devsnek","message":"if i'm typing in the repl faster than the completion can run","date":"2018-11-04T14:46:33.033Z","type":"message"}
{"nick":"gabrielschulhof","reason":"Ping timeout: 244 seconds","date":"2018-11-04T14:46:49.510Z","type":"quit"}
{"nick":"joyee","message":"Hmm, so thinking a bit further - if it's already possible - and to a certain degree, supported (for APM vendors) - to monkey patch modules before they are loaded in the code, what difference does it make to make them dynamically loadable from disk, in code?","date":"2018-11-04T14:48:35.921Z","type":"message"}
{"nick":"devsnek","message":"fs.readFileSync vs cache[id] doesn't make a difference","date":"2018-11-04T14:49:31.355Z","type":"message"}
{"nick":"joyee","message":"I guess the difference is not can't load the modules that are already loaded during bootstrap","date":"2018-11-04T14:49:37.010Z","type":"message"}
{"nick":"joyee","message":"But you can alter the cache as well..","date":"2018-11-04T14:50:03.773Z","type":"message"}
{"nick":"joyee","message":"So the difference is bootstrap, hmm","date":"2018-11-04T14:50:17.573Z","type":"message"}
{"nick":"devsnek","message":"didn't we remove the ability to alter the cache","date":"2018-11-04T14:51:14.969Z","type":"message"}
{"nick":"joyee","message":"But I thought jasnell was talking about command line loader hook options..","date":"2018-11-04T14:51:17.131Z","type":"message"}
{"nick":"devsnek","message":"this reminds me of some stuff bradley is working on","date":"2018-11-04T14:51:43.840Z","type":"message"}
{"nick":"joyee","message":"Oh, right, theoratically you can only alter user land cache","date":"2018-11-04T14:51:49.073Z","type":"message"}
{"nick":"joyee","message":"(But you know there is --expose-internal)","date":"2018-11-04T14:51:59.072Z","type":"message"}
{"nick":"devsnek","message":"--expose-internals is --please-break-my-code","date":"2018-11-04T14:52:14.563Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: race condition? Hmmm, not sure. What input did you give?","date":"2018-11-04T14:54:00.082Z","type":"message"}
{"nick":"devsnek","message":"antsmartian: i haven't run it","date":"2018-11-04T14:54:09.627Z","type":"message"}
{"nick":"devsnek","message":"i'm just noticing that you don't either a) discard the completion output if the buffer changed or b) pause the buffer until the completion finishes","date":"2018-11-04T14:54:38.188Z","type":"message"}
{"nick":"joyee","message":"Giving it a bit more thought, I guess it makes more sense to move part of the initial bootstrap to C++ so that you don't have to load all the modules in JS upfront and kill the monkey-patch opportunity","date":"2018-11-04T14:57:48.193Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: `clearPreview` will clear the preview result on buffer change, before going and asking inspector for the next avaialble preview.","date":"2018-11-04T14:59:57.946Z","type":"message"}
{"nick":"devsnek","message":"antsmartain: is it possible to have a situation where the following happens","date":"2018-11-04T15:00:51.123Z","type":"message"}
{"nick":"devsnek","message":"1) i type \"a\" 2) clearPreview() 3) previewResults() 4) i type \"b\" 5) clearPreview() 6) 7) previewResults() finishes and appends completion for \"a\"","date":"2018-11-04T15:01:50.704Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: No, I doubt that will happen. Because in step number 5) `clearpreview` will definitely clears the buffer so (7) should in-fact get results of `b` (step (4))","date":"2018-11-04T15:10:39.346Z","type":"message"}
{"nick":"devsnek","message":"sorry step 7 is the completion of step 2","date":"2018-11-04T15:11:03.228Z","type":"message"}
{"nick":"devsnek","message":"step 8 would be the next previewResults call","date":"2018-11-04T15:11:13.907Z","type":"message"}
{"nick":"devsnek","message":"and rip step 6","date":"2018-11-04T15:11:41.564Z","type":"message"}
{"nick":"antsmartian","message":"Hmmm, that shouldn't happen from my knowledge. Anyways, do you feel an instance where inspector takes long time to return result? Even in that case I have given the timeout of `500` to handle that case.","date":"2018-11-04T15:14:18.407Z","type":"message"}
{"nick":"devsnek","message":"BridgeAR: another thing broken by the util inspect depth is `require`","date":"2018-11-04T15:16:17.531Z","type":"message"}
{"nick":"devsnek","message":"antsmartian: the more complex the thing its inspecting, the longer it takes","date":"2018-11-04T15:16:49.913Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: Yes, let me play around with that a bit. But most probably, race condition shouldn't happen. Will check once, though.","date":"2018-11-04T15:19:30.226Z","type":"message"}
{"nick":"antsmartian","message":"Also for repl:https://github.com/nodejs/repl, are we not planning to bring up CI? Thought, can add more tests for that repo.","date":"2018-11-04T15:20:15.713Z","type":"message"}
{"nick":"devsnek","message":"its definitely something that should happen","date":"2018-11-04T15:23:13.394Z","type":"message"}
{"nick":"devsnek","message":"i don't have permission to set up travis though","date":"2018-11-04T15:23:46.428Z","type":"message"}
{"nick":"devsnek","message":"antsmartian: i'll look into it soonish i guess","date":"2018-11-04T15:24:36.495Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: Thats a good news! :)","date":"2018-11-04T15:35:52.490Z","type":"message"}
{"nick":"devsnek","message":"what i really want to do is just put the repl in node core","date":"2018-11-04T15:36:21.027Z","type":"message"}
{"nick":"devsnek","message":"its so nice to use","date":"2018-11-04T15:36:25.537Z","type":"message"}
{"nick":"antsmartian","message":"Yup, I'm using it daily.","date":"2018-11-04T15:39:04.960Z","type":"message"}
{"nick":"antsmartian","message":"And I guess history was broken, is that fixed ?","date":"2018-11-04T15:39:20.486Z","type":"message"}
{"nick":"antsmartian","message":"I mean in the new repl","date":"2018-11-04T15:39:24.945Z","type":"message"}
{"nick":"devsnek","message":"oh yeah i haven't added history yt","date":"2018-11-04T15:40:04.925Z","type":"message"}
{"nick":"devsnek","message":"well persistent history","date":"2018-11-04T15:40:10.839Z","type":"message"}
{"nick":"antsmartian","message":"devsnek: Yes. But may be we need to come up with new name like `.node_new_repl_history`. Since people like me use both node repl and new repl, so it shouldn't screw things up.","date":"2018-11-04T15:40:56.912Z","type":"message"}
{"nick":"devsnek","message":"they both run js","date":"2018-11-04T15:41:06.595Z","type":"message"}
{"nick":"devsnek","message":"i don't see a problem","date":"2018-11-04T15:41:09.101Z","type":"message"}
{"nick":"antsmartian","message":"No I meant, if both persist in same history file, then it *might* be a problem.","date":"2018-11-04T15:41:42.932Z","type":"message"}
{"nick":"antsmartian","message":"Also, I have added code for handling mutliline history properly in node core:https://github.com/nodejs/node/pull/22153. Planning to add the same to new repl, thoughts?","date":"2018-11-04T15:42:13.904Z","type":"message"}
{"nick":"antsmartian","message":"May be, will raise PR tomorrow sometime..","date":"2018-11-04T15:42:20.777Z","type":"message"}
{"nick":"antsmartian","message":"addaleax: Hey, thought of giving it a try:https://github.com/nodejs/node/issues/8493. Do you have any roadmap or thoughts for the first iteration?","date":"2018-11-04T15:46:30.086Z","type":"message"}
{"nick":"addaleax","message":"antsmartian: not really... I guess the tricky part is somehow matching doc sections against features?","date":"2018-11-04T15:49:43.761Z","type":"message"}
{"nick":"devsnek","message":"i have a way that might work","date":"2018-11-04T15:50:39.122Z","type":"message"}
{"nick":"devsnek","message":"https://github.com/nodejs/repl/blob/master/src/annotation_map.js","date":"2018-11-04T15:50:53.785Z","type":"message"}
{"nick":"devsnek","message":"arbitrary information can be added to this","date":"2018-11-04T15:50:59.272Z","type":"message"}
{"nick":"antsmartian","message":"addaleax: Hmmm. Not sure how docs are generated and published. If they can generate some sort of intermediate file listing all features(something like devsnek's annotation map), then repl just uses that later?","date":"2018-11-04T15:54:40.723Z","type":"message"}
{"nick":"devsnek","message":"this would allow us to also insert mdn information for builtins","date":"2018-11-04T15:59:09.868Z","type":"message"}
